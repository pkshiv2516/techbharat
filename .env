# === LLM selection ===
USE_OLLAMA=true # true â†’ use local Ollama for chat + embeddings
OLLAMA_HOST=http://localhost:11434
OLLAMA_CHAT_MODEL=llama3.1:8b
OLLAMA_EMBED_MODEL=nomic-embed-text:latest


# If you want to use OpenAI-compatible instead, set USE_OLLAMA=false and configure below
OPENAI_API_KEY=changeme
OPENAI_BASE_URL=
OPENAI_MODEL=gpt-4o-mini


# Chroma
CHROMA_DIR=.chroma
CHROMA_COLLECTION=food_kb


# OCR (set TESSERACT_CMD if not on PATH)
TESSERACT_CMD=C:\Program Files//Tesseract-OCR//tesseract.exe


# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_SERVICE_NAME=food-rating-agent
OTEL_ENVIRONMENT=dev


# API
API_HOST=127.0.0.1
API_PORT=8000
HITL_SECRET=change-me